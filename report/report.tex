\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tabto}
\usepackage{ulem}%better underline
\usepackage{amsmath} %math
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}


\begin{document}
	\title{ECE-GY 9163 ML for Security Project Report}
	\author{Siyuan Shi: N18648680, ss13376 Haotian Yi: N18800809 hy1651}
	\maketitle
	
	*Please note that we have implement two solution: a STRIP based method and a Fine-Pruning based method.
	
	\section{A Solution based on STRIP}
	\subsection{Main idea}
	
	STRIP is a runtime detection method and its idea is based on the fact that trigger have strong effect to force result to be a fixed wrong class. For a test image, we superimpose it with random clean image for several times, if test image is poisoned, the result will be relatively static, otherwise the results will be chaos. And this is measured by entropy. Values of entropy of poison image is small and that of clean image is larger so we can compute a detection boundary.
	
	\subsection{Implementation}
	
	\subsubsection{Main Functions \& how they work}
	\noindent 1. \textbf{superImpose}(overlay\_img, origin\_img, overlay\_weight, back\_weight):\\
	\indent Used to superimpose two images by weights, we use 0.5 and 0.9 as overlay\_weight, back\_weight so trigger won't be weaken.\\
	
	\noindent 2. \textbf{entropyCal}(background, clean\_set, model, overlay\_weight=0.5, back\_weight=0.9):\\
	\indent Used to calculate mean entropy of `background` image superimposed with randomly chosen image in `clean\_set`.\\
	
	\noindent 3. \textbf{getEntropyList}(x\_test, x\_valid, model, overlay\_weight=0.5, back\_weight=0.9):\\
	\indent Used to compute entropy lists of `x\_test` superimposed with random images in `x\_valid`.\\
	
	\noindent 4. \textbf{computeThreshold}(entropy\_benigh, frr=0.07):\\
	\indent Used to compute threshold (detection boundary) between clean and poison image. This is based on the assumption that entropy list is of normal distribution. We fit entropy list into a normal distribution and we assume False Reject Rate to be 7\%, we set the threshold as the value at 7\% of this normal distribution.\\
	
	\subsubsection{Detection Procedure}
	1. First we use \textbf{getEntropyList} (it will call \textbf{entropyCal}) to get a list of entropy for each test image. For each test image, we will superimpose it N times with randomly chosen clean image from validation set. In our implementation, N is set to 10 according to experience and referred material.\\
	2. Then use \textbf{computeThreshold} to compute a detection boundary between entropy distribution of poison and clean image. \\
	3. Use \textbf{entropyCal} (it will call \textbf{superImpose}) to calculate entropy for each test image, if the entropy is less than detection boundary, the test image is judged as backdoored image, otherwise it will be judged as clean, thus we can modify output to N+1 class. 
	
	\subsection{Run code}
	Our code is initially conducted on Colab, but we have encapsulate the code into .py program.
	\textbf{Please run code according to readme.md.}\\
	
	\noindent *Please note that STRIP is a runtime detection method, so we have test it with sunglasses-triggered model but not test with anonymous model, because we do not have test data with anonymous trigger.
	
	
\end{document}